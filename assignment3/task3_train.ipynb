{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example on how you can use a jupyter notebook to train your model :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from assignment3 import utils\n",
    "from assignment3.dataloaders import load_cifar10\n",
    "from assignment3.trainer import Trainer, compute_loss_and_accuracy\n",
    "from assignment3.task2 import create_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task3Model(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_channels,\n",
    "                 num_classes):\n",
    "        \"\"\"\n",
    "            Is called when model is initialized.\n",
    "            Args:\n",
    "                image_channels. Number of color channels in image (3)\n",
    "                num_classes: Number of classes we want to predict (10)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: Implement this function (Task  2a)\n",
    "        num_filters = 8  # Set number of filters in first conv layer\n",
    "        self.num_classes = num_classes\n",
    "        # Define the convolutional layers\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            # [in: 3, out 8, input spatial size: 32x32, output spatial size: 32 x 32 ]\n",
    "            nn.Conv2d(\n",
    "                in_channels=image_channels,\n",
    "                out_channels=num_filters,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "                ),\n",
    "            nn.ReLU(),\n",
    "            # [in: 8, out 16, input spatial size: 32x32, output spatial size: 16 x 16]\n",
    "            nn.Conv2d(\n",
    "                in_channels=num_filters,\n",
    "                out_channels= num_filters * 2,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "                ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "                ),\n",
    "            # [in: 16, out 16 , input spatial size: 16x16, output spatial size: 16x16]\n",
    "            nn.Conv2d(\n",
    "                in_channels=num_filters*2,\n",
    "                out_channels=num_filters*2,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "                ),\n",
    "            nn.ReLU(),\n",
    "            # [in: 16, out 32 , input spatial size: 16x16, output spatial size: 8x8]\n",
    "            nn.Conv2d(\n",
    "               in_channels=num_filters*2,\n",
    "               out_channels=num_filters*4,\n",
    "               kernel_size=5,\n",
    "               stride=1,\n",
    "               padding=2\n",
    "               ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "                ),\n",
    "            #  [in: 32, out 32 , input spatial size: 8x8, output spatial size: 8x8]\n",
    "            nn.Conv2d(\n",
    "                in_channels=num_filters * 4,\n",
    "                out_channels=num_filters * 4,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "                ),\n",
    "            nn.ReLU(),\n",
    "            #  [in: 32, out 32, input spatial size: 8x8, output spatial size: 4x4]\n",
    "            nn.Conv2d(\n",
    "                in_channels=num_filters * 4,\n",
    "                out_channels=num_filters * 4,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "                ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "                ),\n",
    "            nn.Flatten()\n",
    "\n",
    "        )\n",
    "        # The output of feature_extractor will be [batch_size, num_filters, 16, 16]\n",
    "        #self.num_output_features = 32*32*32\n",
    "        self.num_output_features = 32 * 4 * 4\n",
    "        #self.num_output_features = 128 * 4 * 4\n",
    "        # Initialize our last fully connected layer\n",
    "        # Inputs all extracted features from the convolutional layers\n",
    "        # Outputs num_classes predictions, 1 for each class.\n",
    "        # There is no need for softmax activation function, as this is\n",
    "        # included with nn.CrossEntropyLoss\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=self.num_output_features, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=num_classes),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the model\n",
    "        Args:\n",
    "            x: Input image, shape: [batch_size, 3, 32, 32]\n",
    "        \"\"\"\n",
    "        # TODO: Implement this function (Task  2a)\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        batch_size = x.shape[0]\n",
    "        out = x\n",
    "        #print(out.shape)\n",
    "        expected_shape = (batch_size, self.num_classes)\n",
    "        assert out.shape == (batch_size, self.num_classes),\\\n",
    "            f\"Expected output of forward pass to be: {expected_shape}, but got: {out.shape}\"\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Task3aModel(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=32768, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-781987bd883a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0mdataloaders\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m )\n\u001B[0;32m---> 18\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0mcreate_plots\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"task3a\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/home/CV_DL_Jupyter/Computer-Vision-and-Deep-Learning/assignment3/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    176\u001B[0m             \u001B[0;31m# Perform a full pass through all the training samples\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    177\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mX_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_batch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataloader_train\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 178\u001B[0;31m                 \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    179\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_history\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"loss\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglobal_step\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    180\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglobal_step\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/home/CV_DL_Jupyter/Computer-Vision-and-Deep-Learning/assignment3/trainer.py\u001B[0m in \u001B[0;36mtrain_step\u001B[0;34m(self, X_batch, Y_batch)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    154\u001B[0m         \u001B[0;31m# Perform the forward pass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 155\u001B[0;31m         \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    156\u001B[0m         \u001B[0;31m# Compute the cross entropy loss for the batch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss_criterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    743\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 744\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    745\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    746\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-3-436ee506dbb6>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     83\u001B[0m         \u001B[0;31m# TODO: Implement this function (Task  2a)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeature_extractor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 85\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     86\u001B[0m         \u001B[0mbatch_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    743\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 744\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    745\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    746\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    743\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 744\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    745\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    746\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     93\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 94\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     95\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1663\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbias\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1664\u001B[0m         \u001B[0;31m# fused op is marginally faster\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1665\u001B[0;31m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maddmm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1666\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1667\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "    # Set the random generator seed (parameters, shuffling etc).\n",
    "    # You can try to change this and check if you still get the same result! \n",
    "    utils.set_seed(0)\n",
    "    epochs = 10\n",
    "    batch_size = 64\n",
    "    learning_rate = 5e-2\n",
    "    early_stop_count = 4\n",
    "    dataloaders = load_cifar10(batch_size)\n",
    "    model = Task3aModel(image_channels=3, num_classes=10)\n",
    "    trainer = Trainer(\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        early_stop_count,\n",
    "        epochs,\n",
    "        model,\n",
    "        dataloaders\n",
    "    )\n",
    "    trainer.train()\n",
    "    create_plots(trainer, \"task3a\")\n",
    "\n",
    "    #Loading best model and plotting train, val, test accuracy\n",
    "    trainer.load_best_model()\n",
    "    print(trainer.model)\n",
    "    train_loss, train_acc = compute_loss_and_accuracy(\n",
    "        dataloaders[0], trainer.model, loss_criterion=nn.CrossEntropyLoss()\n",
    "    )\n",
    "    val_loss, val_acc = compute_loss_and_accuracy(\n",
    "        dataloaders[1], trainer.model, loss_criterion=nn.CrossEntropyLoss()\n",
    "    )\n",
    "\n",
    "    test_loss, test_accuracy = compute_loss_and_accuracy(\n",
    "        dataloaders[2], trainer.model, loss_criterion=nn.CrossEntropyLoss()\n",
    "    )\n",
    "    print('Performance for best model:')\n",
    "    print('train loss, ', train_loss)\n",
    "    print('train accuracy: ', train_acc)\n",
    "    print('validation loss: ', val_loss)\n",
    "    print('validation accuracy: ', val_acc)\n",
    "    print('test_loss: ', test_loss)\n",
    "    print('test_accuracy: ', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}