{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1a)\n",
    "![](task1/Task1a.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1b) \n",
    "\n",
    "Max Pooling layers reduces the sensitivity to translational variations since they downsample images by extracting the max of a small region of the feature maps. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1c) and d)\n",
    "\n",
    "![](task1/Task1b.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1e) and f)\n",
    "\n",
    "![](task1/Task1ef.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1g)\n",
    "\n",
    "![](task1/Task1g1.jpg)\n",
    "![](task1/Task1g2.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b)\n",
    "Performance for best model:\n",
    "\n",
    "|Training loss:   | Training accuracy: |Validation loss:|Validation accuracy:|Test loss:|Test accuracy:|\n",
    "|:---------------:| :-----------------:|:--------------:|:------------------:|:--------:|:------------:|\n",
    "|0.4837|83.6%|0.775|74.1%|0.782|72.8%|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3a)\n",
    "### Model 1\n",
    "|Layer |Layer type  | Number of channels/ hidden units  |Activation function|\n",
    "|:----:|:----------:| :-------------------------:|:-------------:    |\n",
    "| 1    |Conv2D      | 32                         | ELU   |\n",
    "| 2    |Conv2D      | 64                        | ELU   |\n",
    "| 2    |MaxPool2D   | -                        | -   |\n",
    "| 3    |Conv2D      | 64                         | ELU   |\n",
    "| 4    |Conv2D      | 64                        | ELU   |\n",
    "| 4    |MaxPool2D   | -                        | -   |\n",
    "| 5    |Conv2D      | 64                         | ELU   |\n",
    "| 6    |Conv2D      | 128                        | ELU   |\n",
    "| 6    |MaxPool2D   | -                        | -   |\n",
    "| 7    |Flatten     | -                         | ELU   |\n",
    "| 8    |Linear      | 64                        | ELU   |\n",
    "| 9    |Linear      | 10                        |Softmax  |\n",
    "\n",
    "|Learning rate|Batch size|Optimizer |  Weight regularizaiton|\n",
    "|:----:|:----------:| :--------------:|:-----------:|\n",
    "|  0.05|64   | SGD  |                   None|\n",
    "\n",
    "### Model 2\n",
    "\n",
    "|Layer |Layer type  | Number of channels/ hidden units  |Activation function|\n",
    "|:----:|:----------:| :-------------------------:|:-------------:    |\n",
    "| 1    |Conv2D      | 128                         | ELU   |\n",
    "| 2    |Conv2D      | 128                        | ELU   |\n",
    "| 2    |MaxPool2D   | -                       | -   |\n",
    "| 3    |Conv2D      | 128                         | ELU   |\n",
    "| 4    |Conv2D      | 128                        | ELU   |\n",
    "| 4    |MaxPool2D   | -                        | -   |\n",
    "| 5    |Conv2D      | 128                         | ELU   |\n",
    "| 6    |Conv2D      | 128                        | ELU   |\n",
    "| 6    |MaxPool2D   | -                        | -   |\n",
    "| 7    |Flatten     | -                         | ELU   |\n",
    "| 8    |Linear      | 64                        | ELU   |\n",
    "| 9    |Linear      | 10                        |Softmax  |\n",
    "\n",
    "|Learning rate|Batch size|Optimizer |  Weight regularizaiton|\n",
    "|:----:|:----------:| :--------------:|:-----------:|\n",
    "|  0.05|64   | SGD  |                   None|  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 3b)\n",
    "|Model|Training loss    | Training accuracy  |Validation loss|Validation accuracy|Test loss|Test accuracy|\n",
    "|:---:|:---------------:| :-----------------:|:-------------:|:-----------------:|:-------:|:-----------:|\n",
    "| 1   |0.335|88.7%|0.695|77.3%|0.708|76.5%|\n",
    "| 2   |0.282|90.5%|0.709|77.1%|0.708|77.0%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3c)\n",
    "The methods used for improving performance in the two models were changing the network architecture and activation function. I changed the network architecture from the architecture implemented in task 2 to two architectures with two convolutional layers before each max-pool layer.Stride and padding in convolutional layers is set so that the spatial dimensions remain the same before and after the convolution. In the first model, the number of channels doubles for each MaxPool, from starting at 32 to ending at 128 channels. The second model has 128 channels in all convolutional layers. The performance is quite similar between the two architectures in terms of cross entropy loss and accuracy, only a slightly better performance with 128 channels in each layer. However, training speed is significantly slower with 128 channels in each layer compared with progressively increasing the number of channels. This means that it probably isn't worth training a lot of filters in the first few layers of the network. If the first few layers of a CNN only recognices simple patterns, like lines in different directions, it makes sense that having many channels in the first layers might be wastefull since there are not that many simple patterns that needs to be learnt. In deeper layers where more intricate combination of patterns are recogniced it makes sense that a network should have more filters since there are more combinations of patterns than there are patterns. However, it seems like making the networks deeper in general increased performance significantly from the network in task 2.\n",
    "\n",
    "Both these networks had ELU as activation function. The biggest change in behaviour is seen when comparing the ReLU and ELU activation functions. Both models with ELU reaches higher classification performance quicker than Model 1 with ReLU. However, it seems that the networks with ELU reaches overfitting much earlier than the network with ReLU activation. One can clearly see in the plot in the next task that training loss decreases drastically for each epoch after approximatly 2000 training steps, wheras validation loss flattens out at the same number of training steps for both networks. Model 1 with ReLU activations seems to reach overfitting much later, at approximately 5000 training steps, where the validation loss flattens out at the approximately the same level as the two other models. This does not necessarily mean that ELU is more prone to overfitting than ReLU. We might see this behaviour because ELU activation function seems to be a more efficient activation function compared to ReLU, and the reason that the two models with ELU overfits earlier is because they are quicker to reach their capability to learn. This capability is determined by other parameters of the network like regularization techniques, optimizer etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3d)\n",
    "![](plots/improvement_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3e)\n",
    "![](plots/task3e_plot.png)\n",
    "\n",
    "#### Model performance\n",
    "|Training loss    | Training accuracy  |Validation loss|Validation accuracy|Test loss|Test accuracy|\n",
    "|:---------------:| :-----------------:|:-------------:|:-----------------:|:-------:|:-----------:|\n",
    "|0.309|89.4%|0.569|81.2%|0.594|81.1%|\n",
    "\n",
    "#### Hyperparameters\n",
    "|Learning rate|Batch size|Optimizer |Weight Regularization |\n",
    "|:----:|:----------:     |:--------:|:--------:|\n",
    "|  0.0005|80             | ADAM     | Dropout |\n",
    "\n",
    "\n",
    "#### Model description\n",
    "|Layer |Layer type  | Number of channels/ hidden units  |Activation function|\n",
    "|:----:|:----------:| :-------------------------:|:-------------:    |\n",
    "| 1    |Conv2D      | 32                        | ELU   |\n",
    "| 1    |BatchNorm2D | -                        | -   |\n",
    "| 2    |Conv2D      | 64                       | ELU   |\n",
    "| 2    |BatchNorm2D | -                        | -   |\n",
    "| 2    |MaxPool2D   | -                       | -   |\n",
    "| 3    |Conv2D      | 64                        | ELU   |\n",
    "| 3    |BatchNorm2D | -                        | -   |\n",
    "| 4    |Conv2D      | 64                       | ELU   |\n",
    "| 4    |BatchNorm2D | -                        | -   |\n",
    "| 5    |Conv2D      | 64                        | ELU   |\n",
    "| 5    |BatchNorm2D | -                        | -   |\n",
    "| 6    |Conv2D      | 64                       | ELU   |\n",
    "| 6    |BatchNorm2D | -                        | -   |\n",
    "| 7    |Conv2D      | 128                       | ELU   |\n",
    "| 7    |BatchNorm2D | -                        | -   |\n",
    "| 7    |MaxPool2D   | -                       | -   |\n",
    "| 8    |Conv2D      | 128                       | ELU   |\n",
    "| 8    |BatchNorm2D | -                        | -   |\n",
    "| 9    |Conv2D      | 128                       | ELU   |\n",
    "| 9    |BatchNorm2D | -                        | -   |\n",
    "| 9    |MaxPool2D   | -                        | -   |\n",
    "| 9    |Dropout2D   | -                        | -   |\n",
    "| 10   |Conv2D      | 256                       | ELU   |\n",
    "| 10   |BatchNorm2D | -                        | -   |\n",
    "| 10   |Dropout2D   | -                        | -   |\n",
    "| 11   |Conv2D      | 256                        | ELU   |\n",
    "| 11   |BatchNorm2D | -                        | -   |\n",
    "| 11   |MaxPool2D   | -                        | -   |\n",
    "| 12   |Flatten     | -                         | -   |\n",
    "| 13    |Linear      | 64                        | GELU   |\n",
    "| 14    |Linear      | 10                        |Softmax  |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3f)\n",
    "There are clear signs of overfitting on the aforementioned model. Training loss decreases significantly after approximately 1700 training steps, and continues to drop significantly after the pass of each epoch from this point in the training process. The validation loss still continues to decrease and the validation accuracy continues to increase, but not with the same drastic progress as the training loss. Looking at the final performance averaged over the entire training, validation and test sets, we see that the training loss is more than 0.3 less than test loss, and trainig accuracy is as much as 8.3% higher than the test accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a) Transfer learning with resnet18\n",
    "\n",
    "![](plots/task4_plot.png)\n",
    "\n",
    "#### Hyperparameters\n",
    "|Learning rate|Batch size|Optimizer |\n",
    "|:----:|:----------:| :--------------:|\n",
    "|  5e-4 |32  | Adam  |\n",
    "\n",
    "#### Model performance\n",
    "|Training loss    | Training accuracy  |Validation loss|Validation accuracy|Test loss|Test accuracy|\n",
    "|:---------------:| :-----------------:|:-------------:|:-----------------:|:-------:|:-----------:|\n",
    "|0.129|95.8%|0.319|89.1%|0.355|88.1%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "![](plots/task4b_plot.png)\n",
    "In this illustration we can se the relation between the filters and the feature maps. It seems like three of the filters (filters at index 14, 26 and 49) has learnt to recognize vertical, horisontal and diagonal lines respectively. One can see that the vertical, horisontal and diagonal lines are highlighted in the corresponding feature map Filters at index 42 and 52 seems like they add a blur of opposite values of each other. The corresponding feature maps are somewhat blurred and feature map at index 32  is the negative of the feature map at index 52."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 4c)\n",
    "![](plots/task4c_plot.png)\n",
    "These feature maps of the first ten filters from the last convolutional layer is not easy to make sense of when they're observed with the human eye. They represent some activation in ten specific neurons. Their encoding is not really interpretable just by looking at them like this. However, if we would feed forward multiple  images of zebras these feature maps should look more or less similar for each zebra image, if the network is trained to classify images of zebras. At least that is what we hope. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}