{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "## Task 2a)\n",
    "![](plots/task2_plot.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b)\n",
    "Performance for best model:\n",
    "\n",
    "|Training loss:   | Training accuracy: |Validation loss:|Validation accuracy:|Test loss:|Test accuracy:|\n",
    "|:---------------:| :-----------------:|:--------------:|:------------------:|:--------:|:------------:|\n",
    "|0.4837|83.6%|0.775|74.1%|0.782|72.8%|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3a)\n",
    "### Model 1\n",
    "|Layer |Layer type  | Number of channels/ hidden units  |Activation function|\n",
    "|:----:|:----------:| :-------------------------:|:-------------:    |\n",
    "| 1    |Conv2D      | 32                         | ELU   |\n",
    "| 2    |Conv2D      | 64                        | ELU   |\n",
    "| 2    |MaxPool2D   | -                        | -   |\n",
    "| 3    |Conv2D      | 64                         | ELU   |\n",
    "| 4    |Conv2D      | 64                        | ELU   |\n",
    "| 4    |MaxPool2D   | -                        | -   |\n",
    "| 5    |Conv2D      | 64                         | ELU   |\n",
    "| 6    |Conv2D      | 128                        | ELU   |\n",
    "| 6    |MaxPool2D   | -                        | -   |\n",
    "| 7    |Flatten     | -                         | ELU   |\n",
    "| 8    |Linear      | 64                        | ELU   |\n",
    "| 9    |Linear      | 10                        |Softmax  |\n",
    "\n",
    "|Learning rate|Batch size|Optimizer |\n",
    "|:----:|:----------:| :--------------:|\n",
    "|  0.05|64   | SGD  |\n",
    "\n",
    "### Model 2\n",
    "\n",
    "|Layer |Layer type  | Number of channels/ hidden units  |Activation function|\n",
    "|:----:|:----------:| :-------------------------:|:-------------:    |\n",
    "| 1    |Conv2D      | 128                         | ELU   |\n",
    "| 2    |Conv2D      | 128                        | ELU   |\n",
    "| 2    |MaxPool2D   | -                       | -   |\n",
    "| 3    |Conv2D      | 128                         | ELU   |\n",
    "| 4    |Conv2D      | 128                        | ELU   |\n",
    "| 4    |MaxPool2D   | -                        | -   |\n",
    "| 5    |Conv2D      | 128                         | ELU   |\n",
    "| 6    |Conv2D      | 128                        | ELU   |\n",
    "| 6    |MaxPool2D   | -                        | -   |\n",
    "| 7    |Flatten     | -                         | ELU   |\n",
    "| 8    |Linear      | 64                        | ELU   |\n",
    "| 9    |Linear      | 10                        |Softmax  |\n",
    "\n",
    "|Learning rate|Batch size|Optimizer |\n",
    "|:----:|:----------:| :--------------:|\n",
    "|  0.05|64   | SGD  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 3b)\n",
    "|Model|Training loss    | Training accuracy  |Validation loss|Validation accuracy|Test loss|Test accuracy|\n",
    "|:---:|:---------------:| :-----------------:|:-------------:|:-----------------:|:-------:|:-----------:|\n",
    "| 1   |0.335|88.7%|0.695|77.3%|0.708|76.5%|\n",
    "| 2   |0.282|90.5%|0.709|77.1%|0.708|77.0%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3c)\n",
    "The methods used for improving performance in the two models were changing the network architecture and activation function. I changed the network architecture from the architecture implemented in task 2 to two architectures with two convolutional layers before each max-pool layer.Stride and padding in convolutional layers is set so that the spatial dimensions remain the same before and after the convolution. In the first model, the number of channels doubles for each MaxPool, from starting at 32 to ending at 128 channels. The second model has 128 channels in all convolutional layers. The performance is quite similar between the two architectures in terms of cross entropy loss and accuracy, only a slightly better performance with 128 channels in each layer. However, training speed is significantly slower with 128 channels in each layer compared with progressively increasing the number of channels. This means that it probably isn't worth training a lot of filters in the first few layers of the network. If the first few layers of a CNN only recognices simple patterns, like lines in different directions, it makes sense that having many channels in the first layers might be wastefull since there are not that many simple patterns that needs to be learnt. In deeper layers where more intricate combination of patterns are recogniced it makes sense that a network should have more filters since there are more combinations of patterns than there are patterns. However, it seems like making the networks deeper in general increased performance significantly from the network in task 2.\n",
    "\n",
    "Both these networks had ELU as activation function. The biggest change in behaviour is seen when comparing the ReLU and ELU activation functions. Both models with ELU reaches higher classification performance quicker than Model 1 with ReLU. However, it seems that the networks with ELU reaches overfitting much earlier than the network with ReLU activation. One can clearly see in the plot in the next task that training loss decreases drastically for each epoch after approximatly 2000 training steps, wheras validation loss flattens out at the same number of training steps for both networks. Model 1 with ReLU activations seems to reach overfitting much later, at approximately 5000 training steps, where the validation loss flattens out at the approximately the same level as the two other models. This does not necessarily mean that ELU is more prone to overfitting than ReLU. We might see this behaviour because ELU activation function seems to be a more efficient activation function compared to ReLU, and the reason that the two models with ELU overfits earlier is because they are quicker to reach their capability to learn. This capability is determined by other parameters of the network like regularization techniques, optimizer etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3d)\n",
    "![](plots/improvement_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3e)\n",
    "![](plots/task3e_plot.png)\n",
    "\n",
    "#### Model performance\n",
    "|Training loss    | Training accuracy  |Validation loss|Validation accuracy|Test loss|Test accuracy|\n",
    "|:---------------:| :-----------------:|:-------------:|:-----------------:|:-------:|:-----------:|\n",
    "|0.309|89.4%|0.569|81.2%|0.594|81.1%|\n",
    "\n",
    "#### Hyperparameters\n",
    "|Learning rate|Batch size|Optimizer |Regularization |\n",
    "|:----:|:----------:     |:--------:|:--------:|\n",
    "|  0.0005|80             | ADAM     | Dropout |\n",
    "\n",
    "\n",
    "#### Model description\n",
    "|Layer |Layer type  | Number of channels/ hidden units  |Activation function|\n",
    "|:----:|:----------:| :-------------------------:|:-------------:    |\n",
    "| 1    |Conv2D      | 32                        | ELU   |\n",
    "| 1    |BatchNorm2D | -                        | -   |\n",
    "| 2    |Conv2D      | 64                       | ELU   |\n",
    "| 2    |BatchNorm2D | -                        | -   |\n",
    "| 2    |MaxPool2D   | -                       | -   |\n",
    "| 3    |Conv2D      | 64                        | ELU   |\n",
    "| 3    |BatchNorm2D | -                        | -   |\n",
    "| 4    |Conv2D      | 64                       | ELU   |\n",
    "| 4    |BatchNorm2D | -                        | -   |\n",
    "| 5    |Conv2D      | 64                        | ELU   |\n",
    "| 5    |BatchNorm2D | -                        | -   |\n",
    "| 6    |Conv2D      | 64                       | ELU   |\n",
    "| 6    |BatchNorm2D | -                        | -   |\n",
    "| 7    |Conv2D      | 128                       | ELU   |\n",
    "| 7    |BatchNorm2D | -                        | -   |\n",
    "| 7    |MaxPool2D   | -                       | -   |\n",
    "| 8    |Conv2D      | 128                       | ELU   |\n",
    "| 8    |BatchNorm2D | -                        | -   |\n",
    "| 9    |Conv2D      | 128                       | ELU   |\n",
    "| 9    |BatchNorm2D | -                        | -   |\n",
    "| 9    |MaxPool2D   | -                        | -   |\n",
    "| 9    |Dropout2D   | -                        | -   |\n",
    "| 10   |Conv2D      | 256                       | ELU   |\n",
    "| 10   |BatchNorm2D | -                        | -   |\n",
    "| 10   |Dropout2D   | -                        | -   |\n",
    "| 11   |Conv2D      | 256                        | ELU   |\n",
    "| 11   |BatchNorm2D | -                        | -   |\n",
    "| 11   |MaxPool2D   | -                        | -   |\n",
    "| 12   |Flatten     | -                         | -   |\n",
    "| 13    |Linear      | 64                        | GELU   |\n",
    "| 14    |Linear      | 10                        |Softmax  |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3f)\n",
    "There are clear signs of overfitting on the aforementioned model. Training loss decreases significantly after approximately 1700 training steps, and continues to drop significantly after the pass of each epoch from this point in the training process. The validation loss still continues to decrease and the validation accuracy continues to increase, but not with the same drastic progress as the training loss. Looking at the final performance averaged over the entire training, validation and test sets, we see that the training loss is more than 0.3 less than test loss, and trainig accuracy is as much as 8.3% higher than the test accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "### Hyperparameters\n",
    "|Learning rate|Batch size|Optimizer |eventual data augmentation|Something else|\n",
    "|:----:|:----------:| :-------------------------:|:-------------:    |:----:|\n",
    "|  HGERT |SADFD   | GSDFSD  |HHHJE   | MORRADI|\n",
    "\n",
    "include plot of training and validation loss (like task 2) report test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "![](plots/task4b_plot.png)\n",
    "In this illustration we can se the relation between the filters and the feature maps. It seems like three of the filters (filters at index 14, 2 and 4 from the left) has learnt to recognize vertical, horisontal and diagonal lines respectively. Filters 3 and 5 from the left "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 4c)\n",
    "![](plots/task4c_plot.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
